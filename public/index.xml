<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>About me on Geographer In Nature</title>
    <link>/</link>
    <description>Recent content in About me on Geographer In Nature</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 19 Feb 2019 22:47:58 +0100</lastBuildDate>
    
	<atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>nlrx - The best R package for running NetLogo simulation</title>
      <link>/2019-03-18-nlrx/</link>
      <pubDate>Mon, 18 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019-03-18-nlrx/</guid>
      <description>Intro From the previous blog, you might have noticed the rationale of using high performance computing (HPC), and how fast it is to obtain results compared to our local machines. Having installed all the software requirements on the HPC, today’s post is to simulate a NetLogo model of my Ph.D work in R using an nlrx package(https://ropensci.github.io/nlrx/).
nlrx has promoted its uniqueness for adopting .XML to excecute files that contain various conditions (i.</description>
    </item>
    
    <item>
      <title>How to load gdal packages on the HPC?</title>
      <link>/2019-03-10-how-to-load-gdal-packages-on-the-hpc/</link>
      <pubDate>Sun, 10 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019-03-10-how-to-load-gdal-packages-on-the-hpc/</guid>
      <description>HPC is not a local machine Today’s post is all about setting R on a HPC (High Performance Computing). HPC is also named as a supercomputer because it has many nodes and GB level of memory. People who work with a large set of data or work on parallel processing commonly use the HPC.
I presume most universities and research institutions have this massive system, but if you dont’ have a CompSci background, haven’t used the cluster before (but you are willing to), and you want to use R and spatial tools, this is a good place to start.</description>
    </item>
    
    <item>
      <title>The grass rules in Cambridge</title>
      <link>/pics/thegrassrules/</link>
      <pubDate>Wed, 20 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/pics/thegrassrules/</guid>
      <description>This picture was taken on the 31st of July 2018 at Downing College. Do you see anything other than the yellowy grass? Well here is the hint: * The man with the white shirt is walking furiously towards the men. * The white shirt man is the porter of the college * The men are tourists
Yes, this is actually a scary situation to Cambridgians because only 1) fellows, 2) people talking to a fellow, 3) gardener including gardening robots, and 4) ducks are allowed to walk on college grass.</description>
    </item>
    
    <item>
      <title>How to fill in missing data</title>
      <link>/2018-10-06-how-to-fill-in-missing-data/</link>
      <pubDate>Sat, 06 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018-10-06-how-to-fill-in-missing-data/</guid>
      <description>Filling missing data = Imputation How should we deal with missing data? Should we remove them or keep them?  If NA is hardly noticed in the whole dataset, we can simply ignore them in our analysis by using na.rm = T. If not, then we need to do something to fill the gap.
In statistical terms, the process of replacing(filling) a gap is defined as imputation. There are various ways to imputate missing data, but since my focus is on time-series data, it has to at least take into account the (seasonal) trend to minimise possible errors.</description>
    </item>
    
    <item>
      <title>How to format numbers as fixed width, with leading zeros</title>
      <link>/2018-05-31-how-to-format-numbers-as-fixed-width-with-leading-zeros/</link>
      <pubDate>Thu, 31 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018-05-31-how-to-format-numbers-as-fixed-width-with-leading-zeros/</guid>
      <description>As one of the R Users, I feel quite annoying when I encounter string files which have have counters at the end myfile_1.jpg, myfile_2.jpg,....,myfile_11.jpg.  Why does this bother me? Simple. This is because the sorting system in the R environment only sorts files from their higher digits. For example, in R, the files are sorted in this order: myfile_1.jpg, myfile_11.jpg, ..., myfile_19.jpg, myfile_2.jpg, myfile_20.jpgand so on. But for analytic purposes, we need our first nine files ordered correctly.</description>
    </item>
    
    <item>
      <title></title>
      <link>/research/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/research/</guid>
      <description>Research /*! jQuery v1.11.3 | (c) 2005, 2015 jQuery Foundation, Inc. | jquery.org/license */ !function(a,b){&#34;object&#34;==typeof module&amp;&amp;&#34;object&#34;==typeof module.exports?module.exports=a.document?b(a,!0):function(a){if(!a.document)throw new Error(&#34;jQuery requires a window with a document&#34;);return b(a)}:b(a)}(&#34;undefined&#34;!=typeof window?window:this,function(a,b){var c=[],d=c.slice,e=c.concat,f=c.push,g=c.indexOf,h={},i=h.toString,j=h.hasOwnProperty,k={},l=&#34;1.11.3&#34;,m=function(a,b){return new m.fn.init(a,b)},n=/^[\s\uFEFF\xA0]+|[\s\uFEFF\xA0]+$/g,o=/^-ms-/,p=/-([\da-z])/gi,q=function(a,b){return b.toUpperCase()};m.fn=m.prototype={jquery:l,constructor:m,selector:&#34;&#34;,length:0,toArray:function(){return d.call(this)},get:function(a){return null!=a?0a?this[a+this.length]:this[a]:d.call(this)},pushStack:function(a){var b=m.merge(this.constructor(),a);return b.prevObject=this,b.context=this.context,b},each:function(a,b){return m.each(this,a,b)},map:function(a){return this.pushStack(m.map(this,function(b,c){return a.call(b,c,b)}))},slice:function(){return this.pushStack(d.apply(this,arguments))},first:function(){return this.eq(0)},last:function(){return this.eq(-1)},eq:function(a){var b=this.length,c=+a+(0a?b:0);return this.pushStack(c=0&amp;&amp;bc?[this[c]]:[])},end:function(){return this.prevObject||this.constructor(null)},push:f,sort:c.sort,splice:c.splice},m.extend=m.fn.extend=function(){var a,b,c,d,e,f,g=arguments[0]||{},h=1,i=arguments.length,j=!1;for(&#34;boolean&#34;==typeof g&amp;&amp;(j=g,g=arguments[h]||{},h++),&#34;object&#34;==typeof g||m.isFunction(g)||(g={}),h===i&amp;&amp;(g=this,h--);ih;h++)if(null!=(e=arguments[h]))for(d in e)a=g[d],c=e[d],g!==c&amp;&amp;(j&amp;&amp;c&amp;&amp;(m.isPlainObject(c)||(b=m.isArray(c)))?(b?(b=!1,f=a&amp;&amp;m.isArray(a)?a:[]):f=a&amp;&amp;m.isPlainObject(a)?a:{},g[d]=m.extend(j,f,c)):void 0!==c&amp;&amp;(g[d]=c));return g},m.extend({expando:&#34;jQuery&#34;+(l+Math.random()).replace(/\D/g,&#34;&#34;),isReady:!0,error:function(a){throw new Error(a)},noop:function(){},isFunction:function(a){return&#34;function&#34;===m.type(a)},isArray:Array.isArray||function(a){return&#34;array&#34;===m.type(a)},isWindow:function(a){return null!=a&amp;&amp;a==a.window},isNumeric:function(a){return!m.isArray(a)&amp;&amp;a-parseFloat(a)+1=0},isEmptyObject:function(a){var b;for(b in a)return!1;return!0},isPlainObject:function(a){var b;if(!a||&#34;object&#34;!==m.type(a)||a.nodeType||m.isWindow(a))return!1;try{if(a.constructor&amp;&amp;!j.call(a,&#34;constructor&#34;)&amp;&amp;!j.call(a.constructor.prototype,&#34;isPrototypeOf&#34;))return!1}catch(c){return!1}if(k.ownLast)for(b in a)return j.call(a,b);for(b in a);return void 0===b||j.call(a,b)},type:function(a){return null==a?a+&#34;&#34;:&#34;object&#34;==typeof a||&#34;function&#34;==typeof a?h[i.call(a)]||&#34;object&#34;:typeof a},globalEval:function(b){b&amp;&amp;m.trim(b)&amp;&amp;(a.execScript||function(b){a.eval.call(a,b)})(b)},camelCase:function(a){return a.</description>
    </item>
    
    <item>
      <title>Research</title>
      <link>/research/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/research/</guid>
      <description>My research mainly stands on the quantitative side of geography. This includes miscellaneous GIS approaches, geostatistics (i.e. clustering, spatial autocorrelation), and agent-based modelling. The topics I worked on through my academic path varied from aquatic ecosystem, disease to urban transport, but my recent attention has lied on human-environment interaction, in a pollution context: how air pollution and urbanisation can make people and communities physically and socioeconomically vulnerable.

Main research interests include:  Agent-based modelling GIS Machine learning Nonlinear Statistics Spatial Statistics Big Data Urban Air Pollution Urban Analytics</description>
    </item>
    
  </channel>
</rss>